# ğŸ”§ Como Usar VariÃ¡veis de Ambiente no Projeto

Este guia explica como configurar e usar variÃ¡veis de ambiente de forma segura.

---

## ğŸ“‹ Setup Inicial (Uma Vez)

### 1ï¸âƒ£ Copiar o Template

```bash
# No diretÃ³rio raiz do projeto
cp .env.example .env
```

### 2ï¸âƒ£ Preencher com Suas Credenciais

Edite o arquivo `.env` e substitua os valores:

```bash
# .env (seu arquivo privado)
AWS_ACCESS_KEY_ID=sua_access_key_aqui
AWS_SECRET_ACCESS_KEY=sua_secret_key_aqui
S3_BUCKET_NAME=seu-bucket-s3
# ... etc
```

âš ï¸ **IMPORTANTE**: O arquivo `.env` jÃ¡ estÃ¡ no `.gitignore` e NÃƒO serÃ¡ commitado!

---

## ğŸ Uso em Python (Scripts Locais)

### InstalaÃ§Ã£o

```bash
pip install python-dotenv
```

### CÃ³digo de Exemplo

```python
# local_script.py
import os
from dotenv import load_dotenv

# Carregar variÃ¡veis do arquivo .env
load_dotenv()

# Usar as variÃ¡veis
aws_key = os.getenv('AWS_ACCESS_KEY_ID')
aws_secret = os.getenv('AWS_SECRET_ACCESS_KEY')
bucket_name = os.getenv('S3_BUCKET_NAME')

print(f"Usando bucket: {bucket_name}")
```

---

## â˜ï¸ Uso em AWS Lambda

### ConfiguraÃ§Ã£o

**NÃƒO** use arquivo `.env` na Lambda. Configure via **AWS Console**:

1. AWS Lambda Console â†’ Sua funÃ§Ã£o
2. Configuration â†’ Environment variables
3. Adicionar variÃ¡veis:
   - `S3_BUCKET` = `seu-bucket-name`
   - `S3_PREFIX` = `cvm-transactions-daily`

### CÃ³digo Lambda

```python
# lambda_function.py
import os

# Lambda automaticamente carrega variÃ¡veis de ambiente
S3_BUCKET = os.environ.get('S3_BUCKET')
if not S3_BUCKET:
    raise ValueError("S3_BUCKET environment variable is required!")

# Use normalmente
print(f"Usando bucket: {S3_BUCKET}")
```

---

## ğŸ“Š Uso em Databricks

### âš ï¸ NÃƒO use .env no Databricks!

Use **Databricks Secrets** ao invÃ©s disso.

### Setup Databricks Secrets

```bash
# Criar scope
databricks secrets create-scope --scope aws-credentials

# Adicionar secrets
databricks secrets put --scope aws-credentials --key access-key
databricks secrets put --scope aws-credentials --key bucket-name
```

### CÃ³digo Notebook

```python
# No Databricks Notebook
access_key = dbutils.secrets.get(scope="aws-credentials", key="access-key")
bucket_name = dbutils.secrets.get(scope="aws-credentials", key="bucket-name")

# Configurar Spark
spark.conf.set("fs.s3a.access.key", access_key)
```

---

## ğŸ” VerificaÃ§Ã£o

### Verificar se .env estÃ¡ sendo ignorado

```bash
git status

# .env NÃƒO deve aparecer na lista
# Se aparecer, verifique seu .gitignore
```

### Verificar se variÃ¡veis carregaram

```python
from dotenv import load_dotenv
import os

load_dotenv()
print(os.getenv('S3_BUCKET_NAME'))  # Deve mostrar seu bucket
```

---

## ğŸ›¡ï¸ Checklist de SeguranÃ§a

- [ ] `.env.example` tem apenas placeholders (sem credenciais reais)
- [ ] `.env` estÃ¡ no `.gitignore`
- [ ] `.env` nÃ£o aparece no `git status`
- [ ] Credenciais reais apenas no `.env` local (nunca commit)
- [ ] Lambda usa variÃ¡veis de ambiente via Console
- [ ] Databricks usa Secrets (nÃ£o .env)

---

## ğŸ“ Estrutura Recomendada

```
projeto/
â”œâ”€â”€ .env.example          # âœ… Template (commitado no Git)
â”œâ”€â”€ .env                  # âŒ Privado (NÃƒO commitado)
â”œâ”€â”€ .gitignore            # âœ… ContÃ©m ".env"
â””â”€â”€ seu_script.py         # âœ… Usa load_dotenv()
```

---

## ğŸš¨ Se VocÃª Commitou .env Por Engano

### Remover do histÃ³rico Git

```bash
# Remover arquivo
git rm --cached .env

# Commit a remoÃ§Ã£o
git commit -m "Remove .env file"

# Limpar histÃ³rico (se jÃ¡ deu push)
git filter-branch --force --index-filter \
  "git rm --cached --ignore-unmatch .env" \
  --prune-empty --tag-name-filter cat -- --all

# Force push (CUIDADO!)
git push origin --force --all
```

### Revogar Credenciais

Se credenciais foram expostas, **revogue imediatamente**:

1. AWS IAM Console â†’ Users â†’ Security Credentials
2. Delete Access Key
3. Gere novas credenciais
4. Atualize seu `.env` local

---

## ğŸ“š ReferÃªncias

- [python-dotenv Documentation](https://github.com/theskumar/python-dotenv)
- [AWS Lambda Environment Variables](https://docs.aws.amazon.com/lambda/latest/dg/configuration-envvars.html)
- [Databricks Secrets Guide](docs/databricks_secrets_guide.md)
