# üîí Guia de Seguran√ßa: Configurando Databricks Secrets

## Vis√£o Geral

Este guia explica como configurar credenciais AWS de forma segura no Databricks usando **Secrets** ao inv√©s de hardcoding.

---

## ‚ö†Ô∏è Por Que N√£o Hardcodar Credenciais?

**Riscos de credenciais hardcoded:**
- ‚ùå Exposi√ß√£o em commits Git
- ‚ùå Vazamento no hist√≥rico do GitHub
- ‚ùå Acesso indevido se reposit√≥rio vazar
- ‚ùå Dif√≠cil rota√ß√£o de credenciais
- ‚ùå Viola√ß√£o de compliance (SOC 2, ISO 27001)

**Solu√ß√£o: Databricks Secrets**
- ‚úÖ Credenciais criptografadas
- ‚úÖ Controle de acesso granular
- ‚úÖ Auditoria de uso
- ‚úÖ F√°cil rota√ß√£o
- ‚úÖ Sem risco de commit acidental

---

## üîß Configura√ß√£o Passo a Passo

### 1Ô∏è‚É£ Instalar Databricks CLI

```bash
pip install databricks-cli
```

### 2Ô∏è‚É£ Configurar Autentica√ß√£o

```bash
databricks configure --token
```

Voc√™ precisar√° fornecer:
- **Databricks Host**: `https://seu-workspace.cloud.databricks.com`
- **Token**: Gere em User Settings > Access Tokens

### 3Ô∏è‚É£ Criar Escopo de Secrets

```bash
databricks secrets create-scope --scope aws-credentials
```

**Tipos de escopos:**
- `DATABRICKS` (padr√£o): Gerenciado pelo Databricks
- `AZURE_KEYVAULT`: Integrado com Azure Key Vault

### 4Ô∏è‚É£ Adicionar Secrets

```bash
# Access Key AWS
databricks secrets put --scope aws-credentials --key access-key

# Secret Key AWS
databricks secrets put --scope aws-credentials --key secret-key

# Session Token (se usar credenciais tempor√°rias)
databricks secrets put --scope aws-credentials --key session-token

# Bucket Name
databricks secrets put --scope aws-credentials --key bucket-name
```

**Notas:**
- Cada comando abrir√° um editor para voc√™ colar o valor secreto
- Os valores N√ÉO s√£o exibidos ap√≥s salvos
- Use `--string-value` para valores curtos: `databricks secrets put --scope aws-credentials --key bucket-name --string-value "my-bucket"`

### 5Ô∏è‚É£ Verificar Secrets Criados

```bash
# Listar escopos
databricks secrets list-scopes

# Listar secrets em um escopo
databricks secrets list --scope aws-credentials
```

**Output esperado:**
```
Key name         Last updated
---------------  --------------
access-key       2026-01-11
secret-key       2026-01-11
session-token    2026-01-11
bucket-name      2026-01-11
```

---

## üìù Usando Secrets nos Notebooks

### C√≥digo Python Seguro

```python
# üîí Buscar credenciais do Databricks Secrets
access_key = dbutils.secrets.get(scope="aws-credentials", key="access-key")
secret_key = dbutils.secrets.get(scope="aws-credentials", key="secret-key")
session_token = dbutils.secrets.get(scope="aws-credentials", key="session-token")
bucket_name = dbutils.secrets.get(scope="aws-credentials", key="bucket-name")

# Configurar Spark
spark.conf.set("fs.s3a.access.key", access_key)
spark.conf.set("fs.s3a.secret.key", secret_key)
spark.conf.set("fs.s3a.session.token", session_token)
spark.conf.set("fs.s3a.aws.credentials.provider", "org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider")

# Usar dinamicamente nos paths
path = f"s3a://{bucket_name}/cvm-transactions-daily/"
df = spark.read.csv(path)
```

### C√≥digo Scala Seguro

```scala
val accessKey = dbutils.secrets.get(scope = "aws-credentials", key = "access-key")
val secretKey = dbutils.secrets.get(scope = "aws-credentials", key = "secret-key")

spark.conf.set("fs.s3a.access.key", accessKey)
spark.conf.set("fs.s3a.secret.key", secretKey)
```

---

## üõ°Ô∏è Boas Pr√°ticas

### 1. Controle de Acesso

Criar scopes separados por ambiente:

```bash
databricks secrets create-scope --scope aws-credentials-dev
databricks secrets create-scope --scope aws-credentials-prod
```

### 2. Princ√≠pio do Menor Privil√©gio

Conceda acesso apenas aos usu√°rios necess√°rios:

```bash
databricks secrets put-acl --scope aws-credentials --principal user@company.com --permission READ
```

**N√≠veis de permiss√£o:**
- `MANAGE`: Pode adicionar/remover secrets
- `WRITE`: Pode adicionar secrets
- `READ`: Pode apenas ler secrets

### 3. Rota√ß√£o Regular

Atualize credenciais periodicamente:

```bash
# Deletar secret antigo
databricks secrets delete --scope aws-credentials --key access-key

# Adicionar novo
databricks secrets put --scope aws-credentials --key access-key
```

### 4. Auditoria

Monitore uso de secrets via logs do Databricks:
- Workspace Admin > Audit Logs
- Filtrar por `secretsAccess`

---

## üöÄ Alternativa: IAM Roles (Recomendado para Produ√ß√£o)

Ao inv√©s de Access Keys, use **IAM Roles** anexadas ao cluster:

### Vantagens:
- ‚úÖ Sem necessidade de gerenciar credenciais
- ‚úÖ Rota√ß√£o autom√°tica
- ‚úÖ Mais seguro
- ‚úÖ Auditoria via AWS CloudTrail

### Configura√ß√£o:

1. **Criar IAM Role com permiss√µes S3**:

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:GetObject",
        "s3:PutObject",
        "s3:ListBucket"
      ],
      "Resource": [
        "arn:aws:s3:::your-bucket-name/*",
        "arn:aws:s3:::your-bucket-name"
      ]
    }
  ]
}
```

2. **Anexar Role ao Instance Profile do Cluster**
   - Databricks Admin Console
   - Clusters > Edit > Advanced Options > AWS IAM Role

3. **Configurar Spark**:

```python
spark.conf.set("fs.s3a.aws.credentials.provider", 
               "com.amazonaws.auth.InstanceProfileCredentialsProvider")

# N√£o precisa mais de access_key/secret_key!
bucket_name = dbutils.secrets.get(scope="aws-credentials", key="bucket-name")
path = f"s3a://{bucket_name}/data/"
```

---

## üîç Troubleshooting

### Erro: "SecretNotFoundException"

**Causa**: Secret n√£o existe  
**Solu√ß√£o**:
```bash
databricks secrets list --scope aws-credentials
databricks secrets put --scope aws-credentials --key <missing-key>
```

### Erro: "PermissionDenied"

**Causa**: Usu√°rio n√£o tem permiss√£o no scope  
**Solu√ß√£o**:
```bash
databricks secrets put-acl --scope aws-credentials --principal <user> --permission READ
```

### Erro: "Authentication failed"

**Causa**: Credenciais AWS inv√°lidas ou expiradas  
**Solu√ß√£o**: Renovar credenciais e atualizar secrets

---

## üìö Refer√™ncias

- [Databricks Secrets - Official Docs](https://docs.databricks.com/security/secrets/index.html)
- [AWS IAM Best Practices](https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html)
- [Databricks CLI Reference](https://docs.databricks.com/dev-tools/cli/index.html)
